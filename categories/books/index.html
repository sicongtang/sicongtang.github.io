<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Category: books | BobbyTang Tech Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description">
<meta property="og:type" content="website">
<meta property="og:title" content="BobbyTang Tech Blog">
<meta property="og:url" content="http://sicongtang.github.io/categories/books/">
<meta property="og:site_name" content="BobbyTang Tech Blog">
<meta property="og:description">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="BobbyTang Tech Blog">
<meta name="twitter:description">

  
    <link rel="alternative" href="/atom.xml" title="BobbyTang Tech Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">

  

</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">BobbyTang Tech Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">Learn Share Inspire</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><input type="submit" value="&#xF002;" class="search-form-submit"><input type="hidden" name="q" value="site:http://sicongtang.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-2014-05-21-java-performance-os-monitoring" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/05/21/2014-05-21-java-performance-os-monitoring/" class="article-date">
  <time datetime="2014-05-20T16:16:37.000Z" itemprop="datePublished">May 21 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/05/21/2014-05-21-java-performance-os-monitoring/">Java Performance - OS Monitoring</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Bottom_Up_Approach">Bottom Up Approach</h2>
<p>Bottom up begins at the lowest level of the software stack, at the CPU level looking at statistics such as CPU cache misses, inefficient use of CPU instructions, and then working up the software stack at what constructs or idioms are used by the application.</p>
<h2 id="Choosing_the_Right_CPU_Architecture">Choosing the Right CPU Architecture</h2>
<p>One of the major design points behind the SPARC T-series processors is to address CPU cache misses by introducing multiple hardware threads per core.</p>
<h2 id="CPU_Utilization">CPU Utilization</h2>
<p>A system with a single CPU socket with a quad core processor with hyperthreading disabled will show four CPUs in the GNOME System Monitor and report four virtual processors using the Java API Runtime.availableProcessors(). </p>
<pre><code><span class="title">xosview</span>
vmstat
mpstat
top 
</code></pre><p>Which java thread is consuming CPU?</p>
<pre><code>jstack
</code></pre><h2 id="Monitoring_Linux_CPU_Scheduler_Run_Queue">Monitoring Linux CPU Scheduler Run Queue</h2>
<pre><code>vmstat
</code></pre><h2 id="Memory_Utilization">Memory Utilization</h2>
<pre><code>top
/<span class="keyword">proc</span>/meminf
</code></pre><p>However, the following vmstat output from a Linux system illustrates a system that is experiencing swapping.  P36</p>
<h2 id="Monitoring_Lock_Contention_on_Linux">Monitoring Lock Contention on Linux</h2>
<pre><code>pidstat -w -<span class="keyword">I</span> -p <span class="number">9391</span> <span class="number">5</span>
</code></pre><p>Hence, 3500 divided by 2, the num- ber of virtual processors = 1750. 1750 * 80,000 = 140,000,000. The number of clock cycles in 1 second on a 3.0GHz processor is 3,000,000,000. Thus, the percentage of clock cycles wasted on context switches is 140,000,000/3,000,000,000 = 4.7%. </p>
<p>The cost of a voluntary context switch at a processor clock cycle level is an expensive operation, generally upwards of about 80,000 clock cycles. </p>
<p>Again applying the general guideline of 3% to 5% of clock cycles spent in voluntary context switches implies a Java application that may be suffering from lock contention. </p>
<h2 id="Quick_Lock_Contention_Monitoring">Quick Lock Contention Monitoring</h2>
<h2 id="Isolating_Hot_Locks">Isolating Hot Locks</h2>
<p>A common practice to find contended locks in a Java application has been to periodically take thread dumps and look for threads that tend to be blocked on the same lock across several thread dumps.  </p>
<h2 id="Monitoring_Involuntary_Context_Switches">Monitoring Involuntary Context Switches</h2>
<p>In contrast to voluntary context switching where an executing thread voluntarily takes itself off the CPU, involun- tary thread context switches occur when a thread is taken off the CPU as a result of an expiring time quantum or has been preempted by a higher priority thread. </p>
<p>Involuntary context switches can also be monitored on Linux using <code>pidstat -w</code>. High involuntary context switches are an indication there are more threads ready to run than there are virtual processors available to run them. As a result it is common to observe a high run queue depth in vmstat, high CPU utilization, and a high number of migrations (migrations are the next topic in this section) in conjunction with a large number of involuntary context switches.</p>
<p>On Linux, creation of processor sets and assigning applications to those processor sets can be accomplished using the Linux <code>taskset</code> command.</p>
<h2 id="Monitoring_Thread_Migrations">Monitoring Thread Migrations</h2>
<p>As a general guideline, Java applications scaling across multiple cores or virtual processors and observing migrations greater than 500 per second could benefit from binding Java applications to processor sets.  </p>
<h2 id="Network_I/O_Utilization">Network I/O Utilization</h2>
<pre><code><span class="title">netstat</span> -i 
nicstat
</code></pre><h2 id="Disk_I/O_Utilization">Disk I/O Utilization</h2>
<pre><code>iostat -<span class="keyword">xm</span>
</code></pre><p>One of the challenges with monitoring disk I/O utilization is identifying which files are being read or written to and which application is the source of the disk activity.</p>
<p>At the application level any strategy to minimize disk activity will help such as reducing the number of read and write operations using buffered input and output streams or integrating a caching data structure into the application to reduce or eliminate disk interaction.</p>
<h2 id="Additional_Command_Line_Tools">Additional Command Line Tools</h2>
<pre><code><span class="keyword">sar</span>
</code></pre><h2 id="Monitoring_CPU_Utilization_on_SPARC_T-Series_Systems">Monitoring CPU Utilization on SPARC T-Series Systems</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/05/21/2014-05-21-java-performance-os-monitoring/" data-id="3qr7op5aa7v8498o" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/05/21/2014-05-21-java-performance-os-monitoring/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-04-27-operating-system-concepts-io-system" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/04/27/2014-04-27-operating-system-concepts-io-system/" class="article-date">
  <time datetime="2014-04-27T09:43:57.000Z" itemprop="datePublished">Apr 27 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/04/27/2014-04-27-operating-system-concepts-io-system/">Operating system concepts - IO System</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="I/O_Hardware">I/O Hardware</h2>
<p>The device communicates with the machine via a connection point, or <strong>port</strong> — for example, a serial port.</p>
<p>If devices use a common set of wires, the connection is called a bus. A <strong>bus</strong> is a set of wires and a rigidly defined protocol that specifies a set of messages that can be sent on the wires.</p>
<p>This figure shows a <strong>PCI bus</strong> (the common PC system bus) that connects the processor–memory subsystem to the fast devices and an expansion bus that connects relatively slow devices, such as the keyboard and serial and USB ports.</p>
<img src="https://farm8.staticflickr.com/7406/14029529882_f49ab52235_z.jpg" title="pcbus_structure.png">


<p>A <strong>controller</strong> is a collection of electronics that can operate a port, a bus, or a device. A serial-port controller is a simple device controller. It is a single chip (or portion of a chip) in the computer that controls the signals on the wires of a serial port.</p>
<p>By contrast, a <strong>SCSI bus controller</strong> is not simple. Because the SCSI protocol is complex, the SCSI bus controller is often implemented as a separate circuit board (or a host adapter) that plugs into the computer. It typically contains a processor, microcode, and some private memory to enable it to process the SCSI protocol messages.</p>
<h2 id="Polling_&amp;_Interrupts">Polling &amp; Interrupts</h2>
<p>In many computer architectures, three CPU-instruction cycles are sufficient to poll a device: read a device register, logical–and to extract a status bit, and branch if not zero. But <strong>polling</strong> becomes inefficient when it is attempted repeatedly yet rarely finds a device to be ready for service, while other useful CPU processing remains undone.</p>
<p>The hardware mechanism that enables a device to notify the CPU is called an <strong>interrupt</strong>.</p>
<p>The basic interrupt mechanism works as follows. The CPU hardware has a wire called the <strong>interrupt-request line</strong> that the CPU senses after executing every instruction. When the CPU detects that a controller has asserted a signal on the interrupt-request line, the CPU performs a state save and jumps to the <strong>interrupt-handler routine</strong> at a fixed address in memory.</p>
<p>Another example is found in the implementation of system calls. Usually, a program uses library calls to issue system calls. The library routines check the arguments given by the application, build a data structure to convey the arguments to the kernel, and then execute a special instruction called a <strong>software interrupt</strong>, or <strong>trap</strong>.</p>
<h2 id="Direct_Memory_Access">Direct Memory Access</h2>
<p>For a device that does large transfers, such as a disk drive, it seems wasteful to use an expensive general-purpose processor to watch status bits and to feed data into a controller register one byte at a time—a process termed <strong>programmed I/O (PIO)</strong>. Many computers avoid burdening the main CPU with PIO by offloading some of this work to a special-purpose processor called a <strong>direct-memory-access (DMA) controller</strong>.</p>
<img src="https://farm8.staticflickr.com/7340/14029558121_fb7debb6a5_z.jpg" title="DMA_transfer.png">

<h2 id="Blocking_and_Nonblocking_I/O">Blocking and Nonblocking I/O</h2>
<p>An alternative to a nonblocking system call is an asynchronous system call. An asynchronous call returns immediately, without waiting for the I/O to complete.</p>
<p>The difference between nonblocking and asynchronous system calls is that a nonblocking read() returns immediately with whatever data are available—the full number of bytes requested, fewer, or none at all. An asynchronous read() call requests a transfer that will be performed in its entirety but will complete at some future time. </p>
<img src="https://farm3.staticflickr.com/2927/14032739105_b20504ca80_z.jpg" title="syn_asyn_io.png">

<h2 id="Buffering">Buffering</h2>
<p>A <strong>buffer</strong> is a memory area that stores data being transferred between two devices or between a device and an application.</p>
<p>Buffering is done for three reasons. </p>
<ol>
<li>One reason is to cope with a speed mismatch between the producer and consumer of a data stream.</li>
<li>A second use of buffering is to provide adaptations for devices that have different data-transfer sizes.</li>
<li>A third use of buffering is to support <strong>copy semantics</strong> for application I/O.</li>
</ol>
<p>With <strong>copy semantics</strong>, the version of the data written to disk is guaranteed to be the version at the time of the application system call, independent of any subsequent changes in the application’s buffer. A simple way in which the operating system can guarantee copy semantics is for the write() system call to copy the application data into a kernel buffer before returning control to the application. The disk write is performed from the kernel buffer, so that subsequent changes to the application buffer have no effect.</p>
<h2 id="Caching">Caching</h2>
<p>A <strong>cache</strong> is a region of fast memory that holds copies of data.</p>
<p>When the kernel receives a file I/O request, the kernel first accesses the buffer cache to see whether that region of the file is already available in main memory. If it is, a physical disk I/O can be avoided or deferred.</p>
<h2 id="Transforming_I/O_Requests_to_Hardware_Operations">Transforming I/O Requests to Hardware Operations</h2>
<p>The figure suggests that an I/O operation requires a great many steps that together consume a tremendous number of CPU cycles.</p>
<ol>
<li>A process issues a blocking read() system call to a file descriptor of a file that has been opened previously.</li>
<li>The system-call code in the kernel checks the parameters for correctness. In the case of input, if the data are already available in the buffer cache, the data are returned to the process, and the I/O request is completed.</li>
<li>Otherwise, a physical I/O must be performed. The process is removed from the run queue and is placed on the wait queue for the device, and the I/O request is scheduled. Eventually, the I/O subsystem sends the request to the device driver. Depending on the operating system, the request is sent via a subroutine call or an in-kernel message.</li>
<li>The device driver allocates kernel buffer space to receive the data and schedules the I/O. Eventually, the driver sends commands to the device controller by writing into the device-control registers.</li>
<li>The device controller operates the device hardware to perform the data transfer.</li>
<li>The driver may poll for status and data, or it may have set up a DMA transfer into kernel memory. We assume that the transfer is managed by a DMA controller, which generates an interrupt when the transfer completes.</li>
<li>The correct interrupt handler receives the interrupt via the interrupt- vector table, stores any necessary data, signals the device driver, and returns from the interrupt.</li>
<li>The device driver receives the signal, determines which I/O request has completed, determines the request’s status, and signals the kernel I/O subsystem that the request has been completed.</li>
<li>The kernel transfers data or return codes to the address space of the requesting process and moves the process from the wait queue back to the ready queue.</li>
<li>Moving the process to the ready queue unblocks the process. When the scheduler assigns the process to the CPU, the process resumes execution at the completion of the system call.</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/04/27/2014-04-27-operating-system-concepts-io-system/" data-id="4w7rw08q7wsvauai" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/04/27/2014-04-27-operating-system-concepts-io-system/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-04-23-todo-reading-book-list" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/04/23/2014-04-23-todo-reading-book-list/" class="article-date">
  <time datetime="2014-04-22T22:39:31.000Z" itemprop="datePublished">Apr 23 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/04/23/2014-04-23-todo-reading-book-list/">TODO reading book list</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>List the title of the books with corresponding reference url, for those which begin with <em>/*</em> are highly recommended.</p>
<h2 id="Fundamental">Fundamental</h2>
<ol>
<li>**<a href="http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844/ref=sr_1_1?ie=UTF8&amp;qid=1398206561" title="amazon" target="_blank" rel="external">Introduction to Algorithms</a></li>
<li>*<a href="http://www.amazon.com/Operating-System-Concepts-Abraham-Silberschatz/dp/047050949X/ref=sr_1_1?ie=UTF8&amp;qid=1398206626" title="amazon" target="_blank" rel="external">Operating System Concepts with Java</a></li>
</ol>
<h2 id="Java">Java</h2>
<ol>
<li>**<a href="http://www.amazon.com/Thinking-Java-Edition-Bruce-Eckel/dp/0131872486/ref=sr_1_1?ie=UTF8&amp;qid=1398207134" title="amazon" target="_blank" rel="external">Thinking in Java (4th Edition)</a> prefer to starting with collections&amp;container chapter</li>
<li>*<a href="http://www.amazon.com/Java-Performance-Charlie-Hunt/dp/0137142528/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1398207290" title="amazon" target="_blank" rel="external">Java Performance</a></li>
<li><a href="http://www.amazon.com/Java-Nio-Ron-Hitchens/dp/0596002882/ref=sr_1_1?ie=UTF8&amp;qid=1398207507" title="amazon" target="_blank" rel="external">Java Nio</a></li>
<li><a href="http://www.amazon.com/Java-Message-Service-David-Chappell-ebook/dp/B0026OR3JY/ref=sr_1_1?ie=UTF8&amp;qid=1398207629" title="amazon" target="_blank" rel="external">Java Message Service</a></li>
</ol>
<h2 id="Shell">Shell</h2>
<h2 id="DataBase">DataBase</h2>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/04/23/2014-04-23-todo-reading-book-list/" data-id="qi9th9avhpgpq2lt" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/04/23/2014-04-23-todo-reading-book-list/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-04-23-operating-system-concepts-virtualmemory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/04/23/2014-04-23-operating-system-concepts-virtualmemory/" class="article-date">
  <time datetime="2014-04-22T21:43:26.000Z" itemprop="datePublished">Apr 23 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/04/23/2014-04-23-operating-system-concepts-virtualmemory/">Operating system concepts - VirtualMemory</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Demand_Paging">Demand Paging</h2>
<p>Loading the entire program into memory results in loading the executable code for all options, regardless of whether an option is ultimately selected by the user or not. An alternative strategy is to load pages only as they are needed. This technique is known as <strong>demand paging</strong> and is commonly used in virtual memory systems.</p>
<h2 id="Page_Fault">Page Fault</h2>
<p>A page fault causes the following sequence to occur:</p>
<p><img src="https://farm6.staticflickr.com/5325/13952117776_754a2b4bda.jpg" alt="Alt text" title="Steps_in_handling_a_page_fault.png"></p>
<ol>
<li>Trap to the operating system. </li>
<li>Save the user registers and process state. </li>
<li>Determine that the interrupt was a page fault. </li>
<li>Check that the page reference was legal and determine the location of the page on the disk. </li>
<li>Issue a read from the disk to a free frame:<br>a. Wait in a queue for this device until the read request is serviced.<br>b. Wait for the device seek and/or latency time.<br>c. Begin the transfer of the page to a free frame.</li>
<li>While waiting, allocate the CPU to some other user (CPU scheduling, optional). </li>
<li>Receive an interrupt from the disk I/O subsystem (I/O completed). </li>
<li>Save the registers and process state for the other user (if step 6 is executed). </li>
<li>Determine that the interrupt was from the disk. </li>
<li>Correct the page table and other tables to show that the desired page is now in memory. </li>
<li>Wait for the CPU to be allocated to this process again. </li>
<li>Restore the user registers, process state, and new page table, and then resume the interrupted instruction. </li>
</ol>
<h2 id="Copy-on-Write">Copy-on-Write</h2>
<p>Considering that many child processes invoke the exec() system call immediately after creation, the copying of the parent’s address space may be unnecessary.</p>
<p>Instead, we can use a technique known as <strong>copy-on-write</strong>, which works by allowing the parent and child processes initially to share the same pages. These shared pages are marked as copy-on-write pages, meaning that if either process writes to a shared page, a copy of the shared page is created.</p>
<h2 id="Page_Replacement">Page Replacement</h2>
<ol>
<li>Find the location of the desired page on the disk. </li>
<li>Find a free frame:<br>a. If there is a free frame, use it.<br>b. If there is no free frame, use a page-replacement algorithm to select a victim frame.<br>c. Write the victim frame to the disk; change the page and frame tables accordingly. </li>
<li>Read the desired page into the newly freed frame; change the page and frame tables. </li>
<li>Restart the user process. </li>
</ol>
<p><strong>Page Replacement Algorithm</strong></p>
<ul>
<li>FIFO Page Replacement</li>
<li>Optimal Page Replacement</li>
<li>LRU Page Replacement</li>
<li>LRU-Approximation Page Replacement</li>
<li>Additional-Reference-Bits Algorithm</li>
<li>Second-Chance Algorithm<br>  a. Enhanced Second-Chance Algorithm</li>
<li>Counting-Based Page Replacement<br>  a. least-frequently-used (LFU) page-replacement algorithm<br>  b. most-frequently-used (MFU) page-replacement algorithm</li>
</ul>
<h2 id="Raw_I/O">Raw I/O</h2>
<p>Some operating systems give special programs the ability to use a disk partition as a large sequential array of logical blocks, without any file-system data structures. This array is sometimes called the raw disk, and I/O to this array is termed <strong>raw I/O</strong>.</p>
<p><strong>Raw I/O</strong> bypasses all the file- system services, such as file I/O demand paging, file locking, prefetching, space allocation, file names, and directories.</p>
<h2 id="Thrashing">Thrashing</h2>
<p>In fact, look at any process that does not have “enough” frames. If the process does not have the number of frames it needs to support pages in active use, it will quickly page-fault. At this point, it must replace some page. However, since all its pages are in active use, it must replace a page that will be needed again right away. Consequently, it quickly faults again, and again, and again, replacing pages that it must bring back in immediately.</p>
<p>This high paging activity is called <strong>thrashing</strong>. A process is thrashing if it is spending more time paging than executing.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/04/23/2014-04-23-operating-system-concepts-virtualmemory/" data-id="obds0vxe5bcxfucs" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/04/23/2014-04-23-operating-system-concepts-virtualmemory/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-04-09-operating-system-concepts-mainmemory" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/04/09/2014-04-09-operating-system-concepts-mainmemory/" class="article-date">
  <time datetime="2014-04-08T23:39:27.000Z" itemprop="datePublished">Apr 9 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/04/09/2014-04-09-operating-system-concepts-mainmemory/">Operating system concepts - MainMemory</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Contiguous_Memory_Allocation">Contiguous Memory Allocation</h2>
<p>Problem:</p>
<p>Both the first-fit and best-fit strategies for memory allocation suffer from <strong>external fragmentation</strong>.</p>
<p>The general approach to avoiding this problem is to break the physical memory into fixed-sized blocks and allocate memory in units based on block size. With this approach, the memory allocated to a process may be slightly larger than the requested memory. The difference between these two numbers is <strong>internal fragmentation</strong> — unused memory that is internal to a partition.</p>
<p>Solution:</p>
<p>One solution to the problem of external fragmentation is <strong>compaction</strong>. The goal is to shuffle the memory contents so as to place all free memory together in one large block. Compaction is possible only if relocation is dynamic and is done at execution time.</p>
<p>Another possible solution to the external-fragmentation problem is to permit the logical address space of the processes to be noncontiguous, thus allowing a process to be allocated physical memory wherever such memory is available.</p>
<h2 id="Page_and_Segmentation">Page and Segmentation</h2>
<p><strong>Paging</strong> is a memory-management scheme that permits the physical address space of a process to be noncontiguous. Paging avoids external fragmentation and the need for compaction.</p>
<img src="https://farm8.staticflickr.com/7454/13951470216_7af3187c5c.jpg" title="paging_with_TLB">

<p>The <strong>translation look-aside buffer(TLB)</strong> is associative, high-speed memory. Each entry in the TLB consists of two parts: a key (or tag) and a value. When the associative memory is presented with an item, the item is compared with all keys simultaneously. If the item is found, the corresponding value field is returned.</p>
<p>If the page number is not in the TLB (known as a <strong>TLB miss</strong>), a memory reference to the page table must be made. When the frame number is obtained, we can use it to access memory (Figure 8.11). In addition, we add the page number and frame number to the TLB, so that they will be found quickly on the next reference.</p>
<p><strong>Segmentation</strong> is a memory-management scheme that supports this user view of memory.</p>
<h2 id="Page_Table">Page Table</h2>
<ul>
<li>hierarchical paging</li>
</ul>
<p>Problem&amp;Solution:</p>
<p>For example, consider a system with a 32-bit logical address space. If the page size in such a system is 4 KB (212), then a page table may consist of up to 1 million entries (232/212). Assuming that each entry consists of 4 bytes, each process may need up to 4 MB of physical address space for the page table alone. Clearly, we would not want to allocate the page table contiguously in main memory. One simple solution to this problem is to divide the page table into smaller pieces. We can accomplish this division in several ways.</p>
<pre><code><span class="variable">$ </span>getconf <span class="constant">PAGESIZE</span>
<span class="number">4096</span>
</code></pre><ul>
<li>hashed page tables</li>
</ul>
<p>Problem&amp;Solution:</p>
<p>A common approach for handling address spaces larger than 32 bits is to use a <strong>hashed page table</strong>, with the hash value being the virtual page number.</p>
<ul>
<li>inverted page tables</li>
</ul>
<p>Problem&amp;Solution:</p>
<p>Usually, each process has an associated page table. One of the drawbacks of this method is that each page table may consist of millions of entries. These tables may consume large amounts of physical memory just to keep track of how other physical memory is being used.</p>
<p>Drawbacks:</p>
<p>Although this scheme decreases the amount of memory needed to store each page table, it increases the amount of time needed to search the table when a page reference occurs. </p>
<p>Systems that use inverted page tables have difficulty implementing shared memory. Shared memory is usually implemented as multiple virtual addresses (one for each process sharing the memory) that are mapped to one physical address. This standard method cannot be used with inverted page tables; because there is only one virtual page entry for every physical page, one physical page cannot have two (or more) shared virtual addresses.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/04/09/2014-04-09-operating-system-concepts-mainmemory/" data-id="9fnw1cxymxh9gtbq" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/04/09/2014-04-09-operating-system-concepts-mainmemory/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-04-02-operating-system-concepts-cpu" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/04/02/2014-04-02-operating-system-concepts-cpu/" class="article-date">
  <time datetime="2014-04-01T22:30:57.000Z" itemprop="datePublished">Apr 2 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/04/02/2014-04-02-operating-system-concepts-cpu/">Operating system concepts - CPU</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="CPU_Scheduling">CPU Scheduling</h2>
<p><strong>CPU scheduling</strong> is the task of selecting a waiting process from the ready queue and allocating the CPU to it. The CPU is allocated to the selected process by the dispatcher.</p>
<h2 id="Scheduling_Criteria">Scheduling Criteria</h2>
<ul>
<li>CPU utilization </li>
<li>Throughput</li>
<li>Turnaround time</li>
</ul>
<p>The interval from the time of submission of a process to the time of completion is the turnaround time. <strong>Turnaround time</strong> is the sum of the periods spent waiting to get into memory, waiting in the ready queue, executing on the CPU, and doing I/O.</p>
<ul>
<li>Waiting time</li>
<li>Response time</li>
</ul>
<h2 id="Scheduling_Alogrithm">Scheduling Alogrithm</h2>
<ul>
<li>First-Come, First-Served Scheduling</li>
<li>Shortest-Job-First Scheduling</li>
<li>Priority Scheduling</li>
</ul>
<p>A major problem with priority scheduling algorithms is <strong>indefinite blocking</strong>, or <strong>starvation</strong>.</p>
<p>A solution to the problem of indefinite blockage of low-priority processes is <strong>aging</strong>.</p>
<ul>
<li>Round-Robin Scheduling</li>
<li>Multilevel Queue Scheduling</li>
<li>Multilevel Feedback Queue Scheduling</li>
</ul>
<h2 id="Multiple-Processor/Multicore_Scheduling">Multiple-Processor/Multicore Scheduling</h2>
<ul>
<li>Processor Affinity</li>
</ul>
<p>Because of the high cost of invalidating and repopulating caches, most SMP systems try to avoid migration of processes from one processor to another and instead attempt to keep a process running on the same processor. This is known as <strong>processor affinity</strong>.</p>
<p>Some systems — such as Linux — also provide system calls that support hard affinity, thereby allowing a process to specify that it is not to migrate to other processors.</p>
<p>The main-memory architecture of a system can affect processor affinity issues. Recall the knowledge non-uniform memory access (NUMA) mentioned in previous post, in which a CPU has faster access to some parts of main memory than to other parts. </p>
<ul>
<li>Load Balancing</li>
</ul>
<p>Load balancing attempts to keep the workload evenly distributed across all processors in an SMP system. It is important to note that load balancing is typically only necessary on systems where each processor has its own private queue of eligible processes to execute.</p>
<p>There are two general approaches to load balancing: <strong>push migration</strong> and <strong>pull migration</strong>. Linux runs its load-balancing algorithm every 200 milliseconds (push migration) or whenever the run queue for a processor is empty (pull migration).</p>
<ul>
<li>Memory Stall</li>
</ul>
<p>Researchers have discovered that when a processor accesses memory, it spends a significant amount of time waiting for the data to become available. This situation, known as a <strong>memory stall</strong>, may occur for various reasons, such as a <strong>cache miss</strong> (accessing data that are not in cache memory).</p>
<ul>
<li>Virtualization</li>
</ul>
<p>The virtualization software presents one or more virtual CPUs to each of the virtual machines running on the system and then schedules the use of the physical CPUs among the virtual machines.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/04/02/2014-04-02-operating-system-concepts-cpu/" data-id="3k3upsc9nrh60vxt" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/04/02/2014-04-02-operating-system-concepts-cpu/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-03-25-operating-system-concepts-process-slash-thread" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/03/25/2014-03-25-operating-system-concepts-process-slash-thread/" class="article-date">
  <time datetime="2014-03-24T21:57:31.000Z" itemprop="datePublished">Mar 25 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/03/25/2014-03-25-operating-system-concepts-process-slash-thread/">Operating system concepts - Process/Thread</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="Process_Control_Block">Process Control Block</h2>
<p><strong>Process Control Block</strong> (PCB, also called Task Controlling Block, Task Struct, or Switchframe) is a data structure in the operating system kernel containing the information needed to manage a particular process.</p>
<p>Process state. The state may be new, ready, running, waiting, halted, and so on. </p>
<p>Program counter. The counter indicates the address of the next instruction to be executed for this process. </p>
<p>CPU registers. They include accumulators, index registers, stack pointers, and general-purpose registers, plus any condition-code information. Along with the program counter, this state information must be saved when an interrupt occurs, to allow the process to be continued correctly afterward.</p>
<p>CPU-scheduling information. This information includes a process priority, pointers to scheduling queues, and any other scheduling parameters.</p>
<p>Memory-management information. This information may include such information as the value of the base and limit registers, the page tables, or the segment tables, depending on the memory system used by the operating system. </p>
<p>Accounting information. This information includes the amount of CPU and real time used, time limits, account numbers, job or process numbers, and so on. </p>
<p>I/O status information. This information includes the list of I/O devices allocated to the process, a list of open files, and so on.</p>
<h2 id="Context_Switch">Context Switch</h2>
<p>A <strong>context switch</strong> (also sometimes referred to as a process switch or a task switch) is the switching of the CPU (central processing unit) from one process or thread to another.</p>
<p>A <strong>context</strong> is the contents of a CPU’s registers and program counter at any point in time.</p>
<p>A <strong>program counter</strong> is a specialized register that indicates the position of the CPU in its instruction sequence and which holds either the address of the instruction being executed or the address of the next instruction to be executed, depending on the specific system.</p>
<p>Context switching can be described in slightly more detail as the kernel (i.e., the core of the operating system) performing the following activities with regard to processes (including threads) on the CPU:</p>
<ol>
<li><p>suspending the progression of one process and storing the CPU’s state (i.e., the context) for that process somewhere in memory,</p>
</li>
<li><p>retrieving the context of the next process from memory and restoring it in the CPU’s registers and</p>
</li>
<li><p>returning to the location indicated by the program counter (i.e., returning to the line of code at which the process was interrupted) in order to resume the process.</p>
</li>
</ol>
<h3 id="When_to_switch?">When to switch?</h3>
<p>Context switches can occur only in kernel mode.</p>
<p><strong>Multitasking</strong> 1.)Preemptive schedulers often configure a timer interrupt to fire when a process exceeds its time slice. 2.)This context switch can be triggered by the process making itself unrunnable, such as by waiting for an I/O or synchronization operation to complete.</p>
<p><strong>Interrupt handling</strong> 1.) Hardware interrupt</p>
<p><strong>User and kernel mode switching</strong> may cause context switch.</p>
<h2 id="Multithread_programing">Multithread programing</h2>
<p>Benifits 1.) Responsiveness 2.)Resource sharing 3.) Economy 4.)Scalability</p>
<h2 id="Multicore_Programming">Multicore Programming</h2>
<p>Concerns 1.) Dividing activities 2.)Balance Data splitting 3.)Data dependency 4.)Testing and debugging</p>
<h2 id="Multithread_Model">Multithread Model</h2>
<ul>
<li>Many-to-one model</li>
<li>One-to-one model</li>
</ul>
<p>The nptl(native posix thread library) implementation only uses a 1:1 thread model. The scheduler handles every thread as if it were a process. Therefore only the supported scope is PTHREAD_SCOPE_SYSTEM(Plesae see on Pthread Scheduling label). The default scheduling policy is SCHED_OTHER, which is the default Linux scheduler. The nptl implementation can utilize multiple CPUs.</p>
<ul>
<li>Many-to-many model</li>
<li>Green thread</li>
</ul>
<p>On multi-CPU machines, native threads can run more than one thread simultaneously by assigning different threads to different CPUs. Green threads run on only one CPU.</p>
<p>Green threads, the threads provided by the JVM, run at the user level, meaning that the JVM creates and schedules the threads itself. Therefore, the operating system kernel doesn’t create or schedule them. Instead, the underlying OS sees the JVM only as one thread.</p>
<ul>
<li>Light weight process(LWP)<br>In the traditional meaning of the term, as used in Unix System V and Solaris, a LWP runs in user space on top of a single kernel thread and shares its address space and system resources with other LWPs within the same process.</li>
</ul>
<h2 id="Pthread_Scheduling">Pthread Scheduling</h2>
<p>There are two possible contention scopes. PTHREAD_SCOPE_SYSTEM and PTHREAD_SCOPE_PROCESS. They can be set with pthread_attr_setscope(). The scope of a thread can only be specified before the thread is created.</p>
<ul>
<li>PTHREAD_SCOPE_SYSTEM</li>
</ul>
<p>A thread that has a scope of PTHREAD_SCOPE_SYSTEM will content with other processes and other PTHREAD_SCOPE_SYSTEM threads for the CPU.</p>
<ul>
<li>PTHREAD_SCOPE_PROCESS</li>
</ul>
<p>All threads of a process that have a scope of PTHREAD_SCOPE_PROCESS will be grouped together and this group of threads contents for the CPU. If there is a process with 4 PTHREAD_SCOPE_PROCESS threads and 4 PTHREAD_SCOPE_SYSTEM threds, then each of the PTHREAD_SCOPE_SYSTEM threads will get a fifth of the CPU and the other 4 PTHREAD_SCOPE_PROCESS threads will share the remaing fifth of the CPU. How the PTHREAD_SCOPE_PROCESS threads share their fifth of the CPU among themselves is determined by the scheduling policy and the thread’s priority.</p>
<h2 id="Process_Creation">Process Creation</h2>
<p>When a process creates a new process, two possibilities exist in terms of execution:</p>
<ol>
<li>The parent continues to execute concurrently with its children.</li>
<li>The parent waits until some or all of its children have terminated.</li>
</ol>
<p>There are also two possibilities in terms of the address space of the new process:</p>
<ol>
<li>The child process is a duplicate of the parent process (it has the same program and data as the parent).</li>
<li>The child process has a new program loaded into it.</li>
</ol>
<p>For example, if <code>clone()</code> is passed the flags <code>CLONE FS</code>, <code>CLONE VM</code>, <code>CLONE SIGHAND</code>, and <code>CLONE FILES</code>, the parent and child tasks will share the same file-system information (such as the current working directory), the same memory space, the same signal handlers, and the same set of open files.</p>
<p>However, if none of these flags is set when <code>clone()</code> is invoked, no sharing takes place, resulting in functionality similar to that provided by the <code>fork()</code> system call.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/03/25/2014-03-25-operating-system-concepts-process-slash-thread/" data-id="vd64pkeykqjn6a7f" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/03/25/2014-03-25-operating-system-concepts-process-slash-thread/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-2014-03-05-operating-system-concepts-terminology" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2014/03/05/2014-03-05-operating-system-concepts-terminology/" class="article-date">
  <time datetime="2014-03-04T21:04:59.000Z" itemprop="datePublished">Mar 5 2014</time>
</a>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/books/">books</a>
  </div>

  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2014/03/05/2014-03-05-operating-system-concepts-terminology/">Operating system concepts - Terminology</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>The aim of this post is to review the crucial terms of operating-system and basic interaction of these underlying components.</p>
<p>Before starting with topic, I am going to reveal why I try to read books of OS related at this point. Let me conclude the reasons, first and foremost, various applications in my daily work encounter issues that are associated with LINUX system, such as buffer size, open file limits and unable to create native threads etc. All of these issues point out to the knowledge of OS. Next, Java performance tuning is always based on the operating system concept, like memory management, cpu utilization etc. Furthermore, including all the design concepts are derived from the solution of common issue inside operating system.</p>
<p>Due to these, it is so encouraged to read and go through operating system concept again that I could be inspired and get everything tied. If there are any findings or association with Java, I will make more explanations and comments linked with definitive resource.</p>
<h2 id="1-Storage_Device_Hierarchy">1.Storage Device Hierarchy</h2>
<p>registers — &gt; cache — &gt; main memory (RAM random access memory) — &gt; electronic disk — &gt; magnetic disk — &gt; optical disk — &gt; magnetic tapes</p>
<p><img src="https://farm4.staticflickr.com/3775/13508587744_aa4be3c238_o.png" alt="Alt text" title="cpu_cache_hierarchy"></p>
<h2 id="2-Symmetric_Multiprocessing_(SMP)">2.Symmetric Multiprocessing (SMP)</h2>
<p>SMP systems are tightly coupled multiprocessor systems with a pool of homogeneous processors running independently, each processor executing different programs and working on different data and with capability of sharing common resources (memory, I/O device, interrupt system and so on) and connected using a system bus or a crossbar.</p>
<pre><code><span class="variable">$uname</span> <span class="operator">-a</span>
Linux [nodename] <span class="number">2.6</span>.<span class="number">18</span>-<span class="number">348.18</span>.l.e15 <span class="comment">#1 SMP [date] x86_64 x86_64 GUN/Linux</span>
</code></pre><h2 id="3-Non-uniform_Memory_Access_(NUMA)">3.Non-uniform Memory Access (NUMA)</h2>
<p>NUMA is a computer memory design used in multiprocessing, where the memory access time depends on the memory location relative to the processor. Under NUMA, a processor can access its own local memory faster than non-local memory (memory local to another processor or memory shared between processors). </p>
<h3 id="NUMA_collector_enhancements">NUMA collector enhancements</h3>
<ul>
<li>The Parallel Scavenger garbage collector has been extended to take advantage of machines with NUMA (Non Uniform Memory Access) architecture.<br>The NUMA-aware allocator can be turned on with the <code>-XX:+UseNUMA</code> flag in conjunction with the selection of the Parallel Scavenger garbage collector. The Parallel Scavenger garbage collector is the default for a server-class machine. The Parallel Scavenger garbage collector can also be turned on explicitly by specifying the <code>-XX:+UseParallelGC</code> option.<br>If you want see the detail, please see <a href="http://docs.oracle.com/javase/7/docs/technotes/guides/vm/performance-enhancements-7.html" target="_blank" rel="external">oracle official document</a>.</li>
</ul>
<h2 id="4-Clustering">4.Clustering</h2>
<p>Clustering can be structured asymmetrically or symmetrically. In asymmetric clustering, one machine is in hot-standby mode while the other is running the applications. The hot-standby host machine does nothing but monitor the active server. If that server fails, the hot-standby host becomes the active server. In symmetric mode, two or more hosts are running applications and are monitoring each other. This mode is obviously more efficient, as it uses all of the available hardware. It does require that more than one application be available to run.</p>
<p>For example in real-world scenario: The secondary EMS server is hot-standby mode. Two Weblogic servers are symmetric mode and load balance.</p>
<h2 id="5-Network">5.Network</h2>
<h3 id="5-1-local_area_network_(LAN)">5.1.local area network (LAN)</h3>
<p>A local area network (LAN) is a computer network that user interconnects computers in a limited area such as a home, school, computer laboratory, or office building using network media.</p>
<h3 id="5-2-storage-area_network(SAN)">5.2.storage-area network(SAN)</h3>
<p>SANs are primarily used to enhance storage devices, such as disk arrays, tape libraries, and optical jukeboxes, accessible to servers so that the devices appear like locally attached devices to the operating system.</p>
<h3 id="5-3-wide_area_network_(WAN)">5.3.wide area network (WAN)</h3>
<p>A wide area network (WAN) is a network that covers a broad area (i.e., any telecommunications network that links across metropolitan, regional, or national boundaries) using private or public network transports. WANs are often built using leased lines. WANs can also be built using less costly circuit switching or packet switching methods.</p>
<h2 id="6-Computing_Environments">6.Computing Environments</h2>
<h3 id="6-1-traditional_computing">6.1.traditional computing</h3>
<p><strong>Batch systems</strong> processed jobs in bulk, with predetermined input (from files or other sources of data).</p>
<p><strong>Time-sharing</strong> systems used a timer and scheduling algorithms to rapidly cycle processes through the CPU, giving each user a share of the resources. Time-sharing systems are an extension of multiprogramming wherein CPU scheduling algorithms rapidly switch between jobs, thus providing the illusion that all jobs are running concurrently.</p>
<h3 id="6-2client–Server_computing_(compute_or_file_server_system)">6.2client–Server computing (compute or file server system)</h3>
<p>A <strong>socket</strong> is identified by an IP address concatenated with a port number. Servers implementing specific services (such as telnet, FTP, and HTTP) listen to well-known ports (a telnet server listens to port 23; an FTP server listens to port 21; and a Web, or HTTP, server listens to port 80). </p>
<p>The <strong>remote procedure calls (RPCs)</strong> was designed as a way to abstract the procedure-call mechanism for use between systems with network connections.</p>
<p><strong>Remote method invocation (RMI)</strong> is a Java feature similar to RPCs.</p>
<h3 id="6-3-peer-to-peer_computing">6.3.peer-to-peer computing</h3>
<h3 id="6-4-web-based_computing">6.4.web-based computing</h3>
<h2 id="7-System_Calls">7.System Calls</h2>
<p>In computing, a system call is how a program requests a service from an operating system’s kernel.<br>System calls provide an essential interface between a process and the operating system.<br>System calls can be grouped roughly into six major categories: process control, file manipulation, device manipulation, information maintenance, communications, and protection.</p>
<p>To monitor and trace the system call within the process, we can use strace command in Linux.<br>Strace is used for debugging and troubleshooting the execution of an executable on Linux environment. It displays the system calls used by the process, and the signals received by the process.</p>
<pre><code><span class="variable">$strace</span>
</code></pre><h2 id="8-Interprocess_Communication">8.Interprocess Communication</h2>
<p>There are two common models of interprocess communication:</p>
<h3 id="8-1-message-passing_model">8.1.message-passing model</h3>
<p><strong>Message passing</strong> is useful for exchanging smaller amounts of data, because no conflicts need be avoided.</p>
<p>Message passing may be either blocking or nonblocking— also known as synchronous and asynchronous. 1.)<strong>Blocking send</strong> 2.)<strong>Nonblocking send</strong> 3.)<strong>Blockingreceive</strong> 4.)<strong>Nonblocking receive</strong></p>
<p>Whether communication is direct or indirect, messages exchanged by commu- nicating processes reside in a temporary queue. 1.)<strong>Zero capacity</strong> 2.)<strong>Boundedcapacity</strong> 3.)<strong>Unboundedcapacity</strong></p>
<h3 id="8-2-shared-memory_model">8.2.shared-memory model</h3>
<p>In the <strong>shared-memory</strong> model, processes use shared memory create and shared memory attach system calls to create and gain access to regions of memory owned by other processes.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://sicongtang.github.io/2014/03/05/2014-03-05-operating-system-concepts-terminology/" data-id="uf16pfaobkk3a737" class="article-share-link">Share</a>
      
        <a href="http://sicongtang.github.io/2014/03/05/2014-03-05-operating-system-concepts-terminology/#disqus_thread" class="article-comment-link">Comments</a>
      
      
    </footer>
  </div>
  
</article>


  
  
</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/books/">books</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/devenvsetup-emacs/">devenvsetup emacs</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/devenvsetup-python/">devenvsetup python</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/devenvsetup-ruby/">devenvsetup ruby</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/javascript/">javascript</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/sql/">sql</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/test/">test</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/web/">web</a><span class="category-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/10/">October 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/09/">September 2014</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/07/">July 2014</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/05/">May 2014</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/04/">April 2014</a><span class="archive-list-count">7</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/03/">March 2014</a><span class="archive-list-count">4</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/01/">January 2014</a><span class="archive-list-count">1</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recents</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2014/10/02/hello-world/">Hello World</a>
          </li>
        
          <li>
            <a href="/2014/09/05/2014-09-05-javascript-patterns-notes/">Javascript Patterns Notes</a>
          </li>
        
          <li>
            <a href="/2014/09/02/2014-09-02-mongodb-sql-summary/">mongodb sql summary</a>
          </li>
        
          <li>
            <a href="/2014/07/24/2014-07-24-a-series-of-general-questions-while-designing-webapps/">A series of general questions while designing webapps</a>
          </li>
        
          <li>
            <a href="/2014/07/23/2014-07-23-getting-start-with-emacs/">Getting Start with Emacs</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2014 Bobby Tang<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    
<script>
  var disqus_shortname = 'bobbytang';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">

  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>



<script src="/js/script.js" type="text/javascript"></script>


  </div>
</body>
</html>